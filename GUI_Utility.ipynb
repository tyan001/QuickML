{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_directories(dir_name, labels):\n",
    "\n",
    "    # dir_name - Top level directory name\n",
    "    # labels - labels names. (e.g. cats, dogs, horses)\n",
    "    try:\n",
    "        os.mkdir(dir_name)  # making top level directory\n",
    "    except OSError as e:\n",
    "        print(e.filename, 'exists already')\n",
    "        pass\n",
    "    \n",
    "    train_path = os.path.join(dir_name, 'training')\n",
    "    testing_path = os.path.join(dir_name, 'testing')\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(train_path)  # making training subdirectory\n",
    "    except FileExistsError as e:\n",
    "        print(e.filename, 'exists already')\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(testing_path)  # making testing subdirectory\n",
    "    except FileExistsError as e:\n",
    "        print(e.filename, 'exists already')\n",
    "        pass\n",
    "        \n",
    "    for i in range(len(labels)):  # making training labels and testing labels subdirectory\n",
    "        try:\n",
    "            os.mkdir(os.path.join(train_path, str(labels[i])))\n",
    "        except OSError as e:\n",
    "            print(e.filename, 'exists already')\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            os.mkdir(os.path.join(testing_path, str(labels[i])))\n",
    "        except OSError as e:\n",
    "            print(e.filename, 'exists already')\n",
    "            pass\n",
    "\n",
    "\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "\n",
    "    # SOURCE - Path location where the images are located\n",
    "    # TRAINING - Path location where the training data will be moved to\n",
    "    # TESTING - Path location where the testing data will be moved to\n",
    "    # SPLIT_SIZE = The amount of images going to the training dataset by %.\n",
    "    # (e.g. SPLIT_SIZE = .9: total images = 100, 90 images goes to training directory, 10 images goes to test directory)\n",
    "\n",
    "    testing_file_names = []\n",
    "    file_names = os.listdir(SOURCE)  #\n",
    "    t = round(len(file_names) * (1-SPLIT_SIZE))\n",
    "    random.shuffle(file_names)\n",
    "    for i in range(int(t)):\n",
    "        testing_file_names.append(file_names[i])  # adding the file names for the testing data set\n",
    "        file_names.remove(file_names[i])  # removing the testing data file names\n",
    "    \n",
    "    for jpg in range(len(testing_file_names)):  # using the testing file names to move from source to testing directory\n",
    "        shutil.copy2(os.path.join(SOURCE, testing_file_names[jpg]), TESTING)\n",
    "\n",
    "    for jpg in range(len(file_names)):  # # using the file names to move from source to training directory\n",
    "        shutil.copy2(os.path.join(SOURCE, file_names[jpg]), TRAINING)\n",
    "\n",
    "        \n",
    "def make_dataset(new_dir, labels, src_directories):\n",
    "    make_data_directories(new_dir, labels)\n",
    "    for i in range(len(labels)):\n",
    "        split_data(SOURCE=src_directories[i],\n",
    "                  TRAINING=os.path.join(new_dir, 'training', labels[i]),\n",
    "                  TESTING=os.path.join(new_dir, 'testing', labels[i]),\n",
    "                  SPLIT_SIZE=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_process_dataset(new_dir, labels, src_directories):\n",
    "    make_data_directories(new_dir, labels)\n",
    "    processes = []\n",
    "    for i in range(len(labels)):\n",
    "        training_path = os.path.join(new_dir, 'training', labels[i])\n",
    "        testing_path = os.path.join(new_dir, 'testing', labels[i])\n",
    "        p = mp.Process(target=split_data, args=(src_directories[i], training_path, testing_path, 0.9))        \n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_dir\\training\\rock\n",
      "new_dir\\testing\\rock\n",
      "new_dir\\training\\paper\n",
      "new_dir\\testing\\paper\n",
      "new_dir\\training\\scissor\n",
      "new_dir\\testing\\scissor\n"
     ]
    }
   ],
   "source": [
    "new_dir = 'new_dir'\n",
    "labels = ['rock','paper', 'scissor']\n",
    "for i in range(len(labels)):\n",
    "    print(os.path.join(new_dir, 'training', labels[i]))\n",
    "    print(os.path.join(new_dir, 'testing', labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = 'new_dir' # the new directory name\n",
    "paper_dir = 'rps/paper/' # The next three are the source directories\n",
    "rock_dir = 'rps/rock/'\n",
    "scissor_dir = 'rps/scissors/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = [paper_dir,rock_dir, scissor_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['rock','paper', 'scissor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2.9929604530334473 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "make_dataset(new_dir, labels, src)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = 'blck_ball_dir' # the new directory name\n",
    "blueball = 'Ball_Block_Proj/BlueBall/' \n",
    "blueblock = 'Ball_Block_Proj/BlueBlock/'\n",
    "greenball = 'Ball_Block_Proj/GreenBall/'\n",
    "greenblock = 'Ball_Block_Proj/GreenBlock/'\n",
    "redball = 'Ball_Block_Proj/RedBall/' \n",
    "redblock = 'Ball_Block_Proj/RedBlock/'\n",
    "yellowball = 'Ball_Block_Proj/YellowBall/'\n",
    "yellowblock = 'Ball_Block_Proj/YellowBall/'\n",
    "src = [blueball,blueblock,greenball,greenblock, redball, redblock, yellowball, yellowblock]\n",
    "labels = ['blueball','blueblock', 'greenball', 'greenblock', 'redball','redblock', 'yellowball', 'yellowblock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 23.561182737350464 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "make_dataset(new_dir, labels, src)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = 'blck_ball_dir2' # the new directory name\n",
    "blueball = 'Ball_Block_Proj/BlueBall/' \n",
    "blueblock = 'Ball_Block_Proj/BlueBlock/'\n",
    "greenball = 'Ball_Block_Proj/GreenBall/'\n",
    "greenblock = 'Ball_Block_Proj/GreenBlock/'\n",
    "redball = 'Ball_Block_Proj/RedBall/' \n",
    "redblock = 'Ball_Block_Proj/RedBlock/'\n",
    "yellowball = 'Ball_Block_Proj/YellowBall/'\n",
    "yellowblock = 'Ball_Block_Proj/YellowBall/'\n",
    "src = [blueball,blueblock,greenball,greenblock, redball, redblock, yellowball, yellowblock]\n",
    "labels = ['blueball','blueblock', 'greenball', 'greenblock', 'redball','redblock', 'yellowball', 'yellowblock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ball_Block_Proj/BlueBall/',\n",
       " 'Ball_Block_Proj/BlueBlock/',\n",
       " 'Ball_Block_Proj/GreenBall/',\n",
       " 'Ball_Block_Proj/GreenBlock/',\n",
       " 'Ball_Block_Proj/RedBall/',\n",
       " 'Ball_Block_Proj/RedBlock/',\n",
       " 'Ball_Block_Proj/YellowBall/',\n",
       " 'Ball_Block_Proj/YellowBall/']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.14690876007080078 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    multi_process_dataset(new_dir, labels, src)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
